{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manipulation - Manipulação dos Dados\n",
    "\n",
    "* Lembrete de como ativar o miniconda: conda activate d2l\n",
    "* Para desativar: conda deactivate\n",
    "\n",
    "Formas de armazenar e manipular os dados que iremos utilizar. Para armezanar esses dados podemos utilizar _vetores n-dimensionais_ chamados de **Tensors**.  Para isso, iremos utilizar bastante a biblioteca NumPy:\n",
    "\n",
    "[Guia inicial da biblioteca NumPy.](https://numpy.org/devdocs/user/quickstart.html)\n",
    "\n",
    "**PyTorch** - É um conjunto de ferramentas, bibliotecas e outras coisas que fornece uma estrutura para o desenvolvimento de modelos de IA. É baseado na estrutura dos tensores, citados anteriormente, e fornece várias tools para trabalhar com os dados nesse formato. O tensor apresenta algumas similaridades com os arrays do NumPy.\n",
    "\n",
    "Súmario:\n",
    "- Começando:\n",
    "    - Como criar tensores;\n",
    "- Index e Fatias:\n",
    "    - Como selecionar os elementos;\n",
    "    - Indexação;\n",
    "    - Fatias;\n",
    "- Operações:\n",
    "    - Realizar operações com os dados dos tensores;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Começando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # Estou importanto esse conjunto de ferramentas citado;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um tensor pode ser classificado como um vetor, uma matriz ou um objeto de k<sup>th</sup> order-tensor. Veja abaixo algumas operações:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(12, dtype=torch.float32) \n",
    "# Cria um tensor com valores de 0 a 11, com tipo de float;\n",
    "\n",
    "y = torch.arange(10, 100, 4, dtype=int)\n",
    "# Cria um tensor com valores inteiros de 10 a 100 dando um step de 4;\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para saber qual o número de elementos de um tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.numel()) # Informa o número de elementos;\n",
    "print(y.numel()) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para acessar o comprimento de um tensor ao longo do eixo x:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para acessar o comprimento de um tensor ao lonfgo do eixo x:\n",
    "x.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para mudar o formato de um tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x.reshape(3, 4)\n",
    "print(X) # O tamanho deve continuar o mesmo 12 = 3.4;\n",
    "\n",
    "# Para não ter que especificar o tamanho, podemos usar o -1 no lugar do valor \n",
    "# que queremos que seja calculado automaticamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.zeros((2, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.ones((3, 4, 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para iniciar um tensor de parâmetros aleatórios (que é como começa os parâmetros de uma rede neural geralmente) podemos fazer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randn(5, 4)# Os valores vem de uma distribuição normal.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos também criar um tensor especificando os elementos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index e Fatias:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para acessar, podemos fazer como uma lista normal do Python. O primeiro elemento começa em zero. Para acessar a partir do final pode-se usar valores negativos. E também é possível cortar fatias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[0])\n",
    "print(X[1:3])\n",
    "print(X[-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elementos da matriz por índices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[-1, 2])\n",
    "X[-1, 2] = 499 # Mudando o valor\n",
    "print(X[-1, 2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também é possível mudar tudo com fatias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:2, 1:3] = 42 # Da 0 até a 1 linha, preencher os elementos da posição 1 até a 2 com 12;\n",
    "print(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operações"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que sabemos criar e acessar os dados por meios dos índices, podemos estudar as operações com tensores. \n",
    "\n",
    "Temos as operações **elementwise** que operações escalares serão aplicadas em cada elemento do tensor. Para operações que envolvem 2 tensores, as operações **elementwise** aplicam uma operação binária entre os elementos correspondentes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função abaixo é f : $\\mathbb{R}$ -> $\\mathbb{R}$ com:\n",
    "\n",
    "$$\n",
    "f(x) = e^x\n",
    "$$\n",
    "\n",
    "Onde x representa cada elemento do tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.arange(1, 100, dtype=int)\n",
    "print(t1)\n",
    "\n",
    "print(torch.exp(t1))\n",
    "# Faz a operação e^x com x sendo cada elemento;\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também podemos ter função do tipo f : $\\mathbb{R}, \\mathbb{R}$ -> $\\mathbb{R}$ que chamamos de *binary scalar operator*. Assim, podemos por exemplo receber vetores de $\\mathbb{R}^d$ e realizar operações entre os mesmos. Que é o caso das operações entre elementos correspondentes dos tensores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1, 2, 3, 4])\n",
    "b = torch.tensor([10, 20, 30, 4])\n",
    "\n",
    "print(a + b)\n",
    "print(b - a)\n",
    "print(a * b)\n",
    "print(b / a)\n",
    "print(a ** b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também é possível, ainda nessa categoria de operações, realizar algumas de algebra linear como *dot product* e *multplicação de matrizes*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos também concatenar tensores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.arange(12, dtype=torch.float32).reshape((3,4))\n",
    "print(X) # Temos uma matriz que começa a11 em 0 e termina em 11;\n",
    "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "print(Y) # Temos outra matriz cujas 3 linhas são as acima;\n",
    "\n",
    "# Abaixo estamos concatenando pelo eixo x:\n",
    "print(torch.cat((X, Y), dim=0))\n",
    "# Teremos uma matriz de 6 linhas e 4 colunas;\n",
    "\n",
    "# Abaixo pelo eixo y:\n",
    "print(torch.cat((X, Y), dim=1))\n",
    "# Teremos uma matriz de 8 colunas e 3 linhas;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também é possível utilizar comparadores lógicos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.arange(12, dtype=int).reshape(3, 4)\n",
    "\n",
    "X[0][3] = 11\n",
    "print(X)\n",
    "\n",
    "y = torch.arange(0, 24, 2, dtype=int).reshape(3, 4)\n",
    "print(y)\n",
    "\n",
    "print(X <= y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somando todos os elementos em um só valor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível realizar operações elementares em tensores com formas diferentes. Sob algumas condições, é possível alterar um dos vetores, o expandindo para que fiquem com a mesma forma e depois realizando a operação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(3).reshape((3, 1))\n",
    "b = torch.arange(2).reshape((1, 2))\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que vai ocorrer é o seguinte: a vai ganhar uma nova coluna com os seus valores repetidos e b vai ganhar 2 linhas com seus valores repetidos e essas matrizes irão ser somadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a + b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvando Memória"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazer algumas operações pode fazer com que mais memória seja alocada. Em Python, não é necessário lidar com ponteiros, então utilizamos referências aos objetos. Exemplo:\n",
    "\n",
    "> x = 5\n",
    "\n",
    "Se escrevermos isso em Python, o que estamos fazendo é dizer que x é uma referência ao objeto inteiro contendo o valor 5. \n",
    "\n",
    "O processo de *dereferenciar* refere-se a quando queremos obter o valor de um objeto por meio de uma referência. Exemplo:\n",
    "\n",
    "> y = x + 3\n",
    "\n",
    "A dereferência que ocorre automaticamente nesse caso é a utilização do x (que referencia o objeto inteiro de valor 5)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sejam Y e X referências para dois objetos do tipo tensor. Se fizermos:\n",
    "\n",
    "> Y = X + Y \n",
    "\n",
    "A gente dereferencia Y e faz Y referenciar a nova memória alocada, pois em Python, ele computa primeiro o valor X + Y, aloca a memória para esse resultado e depois faz Y apontar para esse novo local. Ou seja, ainda existe uma memória alocada para o valor anterior de Y. \n",
    "\n",
    "Usando a função id é fácil verificar isso (Essa função retorna o endereço exato de um objeto referenciado na memória)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 5\n",
    "antes = id(x)\n",
    "x = x + 5\n",
    "print(id(x) == antes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos evitar que isso ocorra. Como lidamos com muitos dados, queremos evitar alocar memórias demias, e como usamos muitas referências para um mesmo objeto, desejamos performar as atualizações nele de forma *in place*, para não afetar seu valor em todas as referências. \n",
    "\n",
    "Para realizar essas operações *in place* podemos atribuir o resultado de uma operação ao array Y alocado previamente usando a notação de slice. Veja o exemplo abaixo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = (torch.arange(12)).reshape((3, 4))\n",
    "X = (torch.arange(12)).reshape((3, 4))\n",
    "\n",
    "# Cria um tensor cheio de zeros com o mesmo formato de Y:\n",
    "Z = torch.zeros_like(Y)\n",
    "endereco_antes = id(Z)\n",
    "\n",
    "Z[:] = X + Y\n",
    "endereco_depois = id(Z)\n",
    "\n",
    "print(endereco_antes == endereco_depois)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso o valor de X não fosse utilizado em operações seguintes, tambḿe poderíamos fazer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antes = id(X)\n",
    "X += Y   # Ou X[:] = X + Y\n",
    "depois = id(X)\n",
    "\n",
    "print(antes == depois)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversões para outros Objetos do Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para converter um tensor para um NumPy tensor (ndarray) basta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = X.numpy()\n",
    "print(A)\n",
    "print(type(A))\n",
    "\n",
    "B = torch.from_numpy(A)\n",
    "print(B)\n",
    "print(type(B))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para converter um tensor de tamanho 1 para um escalar do Python, podemos usar as seguintes funções:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.2100])\n",
      "4.210000038146973\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "A = torch.tensor([4.21])\n",
    "print(A)\n",
    "print(float(A))\n",
    "print(int(A))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
