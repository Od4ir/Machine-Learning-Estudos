{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Álgebra Linear\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escalares"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notações para valores escalares:\n",
    "\n",
    "$$ x, y, z \\in \\mathbb{R} $$\n",
    "\n",
    "Escalares são implementados em tensores que contém apenas um elemento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.)\n",
      "tensor(-1.)\n",
      "tensor(12.)\n",
      "tensor(0.7500)\n",
      "tensor(81.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor(3.0)\n",
    "y = torch.tensor(4.0)\n",
    "\n",
    "print(x + y)\n",
    "print(x - y)\n",
    "print(x * y)\n",
    "print(x / y)\n",
    "print(x ** y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vetores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[Como escrever vetores e matrizes em Markdown](https://definirtec.com/latex-criando-uma-matriz-como-faze-lo/)\n",
    "\n",
    "Vetores são como listas de escalares. Os valores da lista são os elementos, entradas. NO exemplo abaixo, $a, b$ e $c$ seriam os escalares, entradas, do vetor:\n",
    "\n",
    "$$ v = \n",
    "\\begin{bmatrix} \n",
    "a \\\\\n",
    "b \\\\\n",
    "c \\\\\n",
    "\\end{bmatrix} $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vetores são tensores de primeira ordem, e é importante lembrar que a indexação na maioria das linguagens de programação começa em zero enquanto em conteúdos teóricos é mais comum começar em um. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(10)\n",
    "print(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seja o vetor:\n",
    "\n",
    "$$ v = \n",
    "\\begin{bmatrix} \n",
    "x_1\\\\\n",
    "\\vdots \\\\\n",
    "x_n\\\\\n",
    "\\end{bmatrix} $$\n",
    "\n",
    "Onde $x_1$ representa o primeiro elemento e $x_n$ representa o enésimo do vetor v. Dizemos que $x \\in \\mathbb{R}^n$, ou seja, $x$ tem $n$ dimensões, $n$ entradas. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse valor é chamado de *dimensionalidade* do vetor. Para saber a *dimensionalidade* de um vetor no Python, basta a função abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para verificar a forma, temos a função abaixo. Ela indica em uma tupla o comprimeto de cada eixo do vetor. No nosso exemplo, no qual o vetor só tem um eixo com 10 elementos, o valor resultante é 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para não ficar confuso, geralmente utiliza-se de *order* (Ordem) para indicar quantos eixos o vetor pode ter e *dimensionalidade* fica para referenciar a quantidade de elementos. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrizes:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrizes são vetores de segunda ordem, ou seja, possuem dois eixos. Podemos representar uma matriz a partir de um vetor utilizando a função reshape. \n",
    "\n",
    "Veja abaixo o código do reshape e a representação de uma matriz $A \\in \\mathbb{R}^{n * m}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$ A =\n",
    "\n",
    "\\begin{pmatrix*}[r] \n",
    "a_{11} & a_{12} & \\dots & a_{1n} \\\\\n",
    "a_{21} & a_{22} & \\dots & a_{2n} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "a_{m1} & a_{m2} & \\dots & a_{mn} \\\\\n",
    "\\end{pmatrix*} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.arange(18).reshape(3, 6)\n",
    "print(A)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fazer a **transposta** de uma matriz, que é tratar as linhas como colunas e as colunas como linhas, basta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  6, 12],\n",
      "        [ 1,  7, 13],\n",
      "        [ 2,  8, 14],\n",
      "        [ 3,  9, 15],\n",
      "        [ 4, 10, 16],\n",
      "        [ 5, 11, 17]])\n"
     ]
    }
   ],
   "source": [
    "print(A.T)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matrizes Simétricas** são aquelas que são iguais as suas transpostas. Ou seja $A = A^{T}$. Veja como verificar isso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True],\n",
      "        [True, True, True],\n",
      "        [True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]])\n",
    "print(A == A.T)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensores:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além de vetores de primeira e segunda ordem (matrizes), será necessário trabalhar com vetores de odens maiores. Um exemplo de dado que utiliza um vetor de terceira ordem são os dados relativos a imagens:\n",
    "- Altura;\n",
    "- Largura;\n",
    "- Channel - que guarda a intensidade de cada cor (RGB - Red, Green e Blue);\n",
    "\n",
    "Esse é só um exemplo de como podemos trabalhar com imagens e a motivação por de trás da necessidade de tensores de ordens maiores. Veja abaixo um tensor de 3º ordem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(24).reshape(2, 3, 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É como se fosse um paralelepipedo com cada camada sendo uma matriz, e tendo no total, 2 dessas camadas de matriz. Como se fosse uma fila de matrizes. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propriedades Básicas de Aritmética de Tensores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veremos algumas operações básicas com tensores:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.]])\n",
      "A + B =  tensor([[ 0.,  2.,  4.],\n",
      "        [ 6.,  8., 10.]])\n",
      "2 * A =  tensor([[ 0.,  2.,  4.],\n",
      "        [ 6.,  8., 10.]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.arange(6, dtype=torch.float32).reshape(2, 3)\n",
    "B = A.clone()  # Copia A em B, alocando uma nova memória; \n",
    "\n",
    "print(A)\n",
    "\n",
    "print(\"A + B = \", A + B)\n",
    "print(\"2 * A = \", 2*A)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hadamard Product:\n",
    "\n",
    "Multiplica o elemento $a_{ijk...}$ pelo elemento $b_{ijk...}$ e forma um novo tensor. É chamado de Hadamard Product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A * B =  tensor([[ 0.,  1.,  4.],\n",
      "        [ 9., 16., 25.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"A * B = \", A * B)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operações de Tensor com Escalar:\n",
    "\n",
    "As operações são realizadas somando, subtraindo, dividindo ou multiplicando o escapar por todo elemento do tensor. Veja abaixo um exemplo da multipliação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14, 15],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]]])\n",
      "C * 100 =  tensor([[[   0,  100,  200,  300],\n",
      "         [ 400,  500,  600,  700],\n",
      "         [ 800,  900, 1000, 1100]],\n",
      "\n",
      "        [[1200, 1300, 1400, 1500],\n",
      "         [1600, 1700, 1800, 1900],\n",
      "         [2000, 2100, 2200, 2300]]])\n"
     ]
    }
   ],
   "source": [
    "C = torch.arange(24).reshape(2, 3, 4)\n",
    "print(C)\n",
    "\n",
    "print(\"C * 100 = \", C * 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduction - Redução:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcular a soma de todos os elementos de um vetor de dimensionalidade $n$:\n",
    "\n",
    "$$\\sum_{i=1}^{n} x_i$$\n",
    "\n",
    "Para obter esse valor, tem uma função pronta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.,\n",
      "        15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27., 28.,\n",
      "        29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40., 41., 42.,\n",
      "        43., 44., 45., 46., 47., 48., 49., 50.], dtype=torch.float64)\n",
      "tensor(1275., dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "X = torch.arange(50, dtype=float)\n",
    "X[:] = X + 1\n",
    "print(X)\n",
    "print(X.sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para um tensor de forma arbitrária, a soma devolve a soma de todos os elementos do tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3,  4,  5,  6],\n",
      "         [ 7,  8,  9, 10, 11, 12]],\n",
      "\n",
      "        [[13, 14, 15, 16, 17, 18],\n",
      "         [19, 20, 21, 22, 23, 24]],\n",
      "\n",
      "        [[25, 26, 27, 28, 29, 30],\n",
      "         [31, 32, 33, 34, 35, 36]]])\n",
      "tensor(666)\n"
     ]
    }
   ],
   "source": [
    "Y = torch.arange(36).reshape(3, 2, 6)\n",
    "Y[:] = Y + 1\n",
    "print(Y)\n",
    "\n",
    "print(Y.sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível também especificar em quais eixos se deseja realizar a soma, para isso, basta especificar por meio do índice do eixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 6])\n",
      "tensor([[39, 42, 45, 48, 51, 54],\n",
      "        [57, 60, 63, 66, 69, 72]])\n",
      "tensor([[ 8, 10, 12, 14, 16, 18],\n",
      "        [32, 34, 36, 38, 40, 42],\n",
      "        [56, 58, 60, 62, 64, 66]])\n",
      "tensor([[ 21,  57],\n",
      "        [ 93, 129],\n",
      "        [165, 201]])\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)\n",
    "print(Y.sum(axis=0)) # Ao longo do eixo z; (3)\n",
    "print(Y.sum(axis=1)) # Ao longo do eixo y; (2)\n",
    "print(Y.sum(axis=2)) # Ao longo do eixo x; (6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
